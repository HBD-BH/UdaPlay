{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fdd0bcb",
   "metadata": {},
   "source": [
    "# Udaplay Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9325b035",
   "metadata": {},
   "source": [
    "## Part 02 - Agent\n",
    "\n",
    "In this part of the project, you'll use your VectorDB to be part of your Agent as a tool.\n",
    "\n",
    "You're building UdaPlay, an AI Research Agent for the video game industry. The agent will:\n",
    "1. Answer questions using internal knowledge (RAG)\n",
    "2. Search the web when needed\n",
    "3. Maintain conversation state\n",
    "4. Return structured outputs\n",
    "5. Store useful information for future use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b42de90",
   "metadata": {},
   "source": [
    "### Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd10c06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For example: \n",
    "import os\n",
    "from dotenv import load_dotenv                  # For loading environment variables from .env file\n",
    "from datetime import datetime                   # For websearch metadata assignment\n",
    "\n",
    "from typing import List, Dict\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from lib.agents import Agent                    # For Agent class\n",
    "from lib.llm import LLM                         # For Large Language Model\n",
    "from lib.messages import UserMessage, SystemMessage, BaseMessage\n",
    "from lib.tooling import tool                    # For defining tools    \n",
    "from lib.parsers import PydanticOutputParser    # To return structured output from LLM\n",
    "\n",
    "from chromadb import PersistentClient           # For Vector Database\n",
    "# import chromadb\n",
    "\n",
    "from tavily import TavilyClient                 # For Web Search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87e465d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "OPENAI_BASE_URL = os.getenv(\"OPENAI_BASE_URL\")\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "VOCAREUM_OPENAI_API_KEY=os.getenv(\"VOCAREUM_OPENAI_API_KEY\")\n",
    "VOCAREUM_BASE_URL=os.getenv(\"VOCAREUM_BASE_URL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0955006",
   "metadata": {},
   "source": [
    "Setting up ChromaDB paths and names. Should be consistent with what you used in the `Udaplay_01.ipynb` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1614303d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHROMADB_PATH = \"chromadb\"\n",
    "CHROMADB_COLLECTION_NAME = \"udaplay\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce364221",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27de4729",
   "metadata": {},
   "source": [
    "### Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ab2dac",
   "metadata": {},
   "source": [
    "Build at least 3 tools:\n",
    "- retrieve_game: To search the vector DB\n",
    "- evaluate_retrieval: To assess the retrieval performance\n",
    "- game_web_search: If no good, search the web\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4f14cd",
   "metadata": {},
   "source": [
    "#### Retrieve Game Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b25c36dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def retrieve_game(query: str, n_results: int=4) -> List:\n",
    "    \"\"\"\n",
    "#    Semantic search: Finds most relevant results in the vector DB\n",
    "#    args:\n",
    "#    - query: a question about game industry. \n",
    "#    - n_results: number of results to return (default is 4)\n",
    "#\n",
    "#    You'll receive results as list. Each element contains:\n",
    "#    - Platform: like Game Boy, Playstation 5, Xbox 360...)\n",
    "#    - Name: Name of the Game\n",
    "#    - YearOfRelease: Year when that game was released for that platform\n",
    "#    - Description: Additional details about the game\n",
    "    \"\"\"\n",
    "\n",
    "    # collection.query(\n",
    "        # query_texts=[query],\n",
    "        # n_results=n_results,\n",
    "        # include=['metadatas', 'documents', 'distances'] # TODO: look at collection.peek() to understand this better.\n",
    "    # )\n",
    "\n",
    "    # These have been created in Phase 1\n",
    "    chroma_client = PersistentClient(path=CHROMADB_PATH)\n",
    "    collection = chroma_client.get_collection(CHROMADB_COLLECTION_NAME)\n",
    "\n",
    "    results = collection.query(\n",
    "        query_texts=[query], \n",
    "        n_results=5\n",
    "        )\n",
    "    \n",
    "    return results[\"documents\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cf8a174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To test the function\n",
    "# query = \"Tell me about Gran Turismo\"\n",
    "# response = retrieve_game(query)\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910dc945",
   "metadata": {},
   "source": [
    "#### Evaluate Retrieval Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d9d014b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvaluationReport(BaseModel):\n",
    "    useful: bool = Field(..., description=\"Indicates if the retrieved documents are useful for answering the question\")\n",
    "    description: str = Field(..., description=\"Detailed explanation of the evaluation result, including why the documents are or are not useful\")\n",
    "\n",
    "@tool\n",
    "def evaluate_retrieval(question: str, retrieved_docs: list) -> EvaluationReport:\n",
    "    \"\"\"\n",
    "    Based on the user's question and on the list of retrieved documents, this function \n",
    "    will analyze the usability of the documents to respond to that question. \n",
    "    args: \n",
    "    - question: original question from user\n",
    "    - retrieved_docs: retrieved documents most similar to the user query in the Vector Database\n",
    "    Outputs:\n",
    "    EvaluationReport:\n",
    "    - useful: whether the documents are useful to answer the question\n",
    "    - description: description about the evaluation result\n",
    "    \"\"\"\n",
    "\n",
    "    system_prompt = \"\"\"\n",
    "        You are an expert in evaluating the usability of documents for answering user queries.\n",
    "        Your task is to evaluate if the provided sources are enough to respond the user query.\n",
    "        Give a detailed explanation, so it's possible to take an action to accept it or not.\n",
    "    \"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "        User query:\\n{question}\\n\n",
    "        Retrieved documents:\\n{retrieved_docs}\n",
    "    \"\"\"\n",
    "\n",
    "    messages = [\n",
    "        SystemMessage(content=system_prompt),\n",
    "        UserMessage(content=user_prompt)\n",
    "    ]\n",
    "\n",
    "    llm_judge = LLM(\n",
    "        model=\"gpt-4.1-nano\",\n",
    "        temperature=0.0,\n",
    "        api_key=VOCAREUM_OPENAI_API_KEY,\n",
    "        base_url=VOCAREUM_BASE_URL\n",
    "    )\n",
    "\n",
    "    ai_message = llm_judge.invoke(input=messages, response_format=EvaluationReport)\n",
    "    parser = PydanticOutputParser(model_class=EvaluationReport)\n",
    "    return parser.parse(ai_message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5b5d7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To test the function\n",
    "# response_valid = evaluate_retrieval(query, response)\n",
    "# print(response_valid.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7935a26",
   "metadata": {},
   "source": [
    "#### Game Web Search Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ad698aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetaData(BaseModel):\n",
    "    timestamp: str = Field(..., description=\"The time the web search was performed, in ISO format (YYYY-MM-DD HH:MM:SS.mmmmmm)\")\n",
    "    query: str = Field(..., description=\"The original search query\")\n",
    "\n",
    "class WebSearchResult(BaseModel):\n",
    "    answer: str = Field(..., description=\"Answer to the search query\")\n",
    "    results: List[Dict] = Field(..., description=\"List of search results\")\n",
    "    search_metadata: MetaData  = Field(..., description=\"Metadata of the web search\")\n",
    "\n",
    "# Modified from Course module 06 solution notebook (Web Search with Tavily)\n",
    "@tool\n",
    "def game_web_search(query: str, search_depth: str = \"advanced\") -> Dict:\n",
    "    \"\"\"\n",
    "    Search the web using Tavily API.\n",
    "    args:\n",
    "        query (str): Search query\n",
    "        search_depth (str): Type of search - 'basic' or 'advanced' (default: advanced)\n",
    "    Output: \n",
    "    WebSearchResult:\n",
    "    - answer (str): Direct answer to the query, if available\n",
    "    - results (List[Dict]): List of search results, each containing:\n",
    "    - search_metadata (Dict): Metadata about the search, including timestamp and query\n",
    "    \"\"\"\n",
    "    client = TavilyClient(api_key=TAVILY_API_KEY)\n",
    "    \n",
    "    # Perform the search\n",
    "    search_result = client.search(\n",
    "        query=query,\n",
    "        search_depth=search_depth,\n",
    "        include_answer=True,\n",
    "        include_raw_content=False,\n",
    "        include_images=False\n",
    "    )\n",
    "    \n",
    "    # Format the results\n",
    "    formatted_results = {\n",
    "        \"answer\": search_result.get(\"answer\", \"\"),\n",
    "        \"results\": search_result.get(\"results\", []),\n",
    "        \"search_metadata\": {\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"query\": query\n",
    "        }\n",
    "    }\n",
    "    # metadata_parser = PydanticOutputParser(model_class=WebSearchResult)\n",
    "    # validated_results = metadata_parser.parse(ai_message=AIMessage(content=str(formatted_results)))\n",
    "    validated_results = WebSearchResult(**formatted_results)\n",
    "\n",
    "    return validated_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a80af3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To test the function\n",
    "# web_search_response = game_web_search(query)\n",
    "# print(web_search_response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df844b3b",
   "metadata": {},
   "source": [
    "### Creating and invoking the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31c56281",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [retrieve_game, evaluate_retrieval, game_web_search]\n",
    "\n",
    "instructions = f\"\"\"\n",
    "    You are a helpful assistant that answers questions about video games. \n",
    "    Users will ask you about video games, including names, contents, publishing years, etc.\n",
    "\n",
    "    You should first check whether an answer to the question is possible based on your knowledge (stored as a VectorDB), using the `retrieve_game` tool.\n",
    "    After using `retrieve_game`, always run `evaluate_retrieval` to check whether the retrieved information is actually useful. \n",
    "    If the result of `evaluate_retrieval` is that the information is not useful, use your `game_web_search` tool to find an answer on the web. \n",
    "\n",
    "    Final output: \n",
    "    - In your final answer, always state whether the answer was from the curated database or from the open web.\n",
    "    - If you found an answer on the web, cite the highest-ranked URL you found, so that users can go look up the primary source. The users don't have access to the search results, so cite a URL with link. Always include a link in your answer.\n",
    "    - Do not make up facts.\n",
    "\n",
    "    EXAMPLEs for final answer: \n",
    "    - Mario Kart is a racing game developed for the Nintendo GameCube. This information was retrieved from the internal database. \n",
    "    - Zelda: Tears of the Kingdom was released in 2023. This information was found on this website: https://www.nintendo.com/en-gb/Games/Nintendo-Switch-games/The-Legend-of-Zelda-Tears-of-the-Kingdom-1576884.html. \n",
    "\"\"\"\n",
    "\n",
    "web_agent = Agent(\n",
    "    model_name=\"gpt-4.1-nano\",\n",
    "    instructions=instructions,\n",
    "    tools=tools,\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=OPENAI_BASE_URL,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9eefa18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_messages(messages: List[BaseMessage]):\n",
    "    for m in messages:\n",
    "        print(f\" -> (role = {m.role}, content = {m.content}, tool_calls = {getattr(m, 'tool_calls', None)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7db9cc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_agent_answer(messages: List[BaseMessage]):\n",
    "    # Get tool calls invoked\n",
    "    tools_called = []\n",
    "    index_last_query = next(i for i, m in reversed(list(enumerate(messages))) if m.role == 'user')\n",
    "    # print(f\"index: {index_last_query} out of {len(messages)}\") # To ensure the previous line works as expected\n",
    "    for m in messages[index_last_query:]: \n",
    "        if getattr(m, 'tool_calls', None):\n",
    "            tools_called.append(m.tool_calls[0].function.name)\n",
    "    print(f\"Final answer from the agent: {messages[-1].content}\")\n",
    "    print(f\"The agent called these tools (in order): {tools_called}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c285ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: message_prep\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Terminating: __termination__\n",
      "------------------------------\n",
      "Query: When were Pokémon Gold and Silver released?\n",
      "Final answer from the agent: Pokémon Gold and Silver were released in 1999. This information was retrieved from the internal database.\n",
      "The agent called these tools (in order): ['retrieve_game', 'evaluate_retrieval']\n",
      "--------------------------------------------------\n",
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: message_prep\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Terminating: __termination__\n",
      "------------------------------\n",
      "Query: Thanks, and which version was released in 2002?\n",
      "Final answer from the agent: The Pokémon game released in 2002 was Pokémon Ruby and Sapphire. This information was retrieved from the internal database.\n",
      "The agent called these tools (in order): ['retrieve_game', 'evaluate_retrieval']\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "query1=\"When were Pokémon Gold and Silver released?\"\n",
    "sessionid1=\"pokemon\"\n",
    "\n",
    "run1 = web_agent.invoke(\n",
    "    query=query1,\n",
    "    session_id=sessionid1\n",
    ")\n",
    "\n",
    "messages = run1.get_final_state()[\"messages\"]\n",
    "# print(\"\\nMessages from run 1:\")\n",
    "# print_messages(messages)              # To print much more information on intermediate steps\n",
    "print(\"-\" * 30)\n",
    "print(f\"Query: {query1}\")\n",
    "print_agent_answer(messages)\n",
    "print(\"-\" * 50)\n",
    "\n",
    "query1_followup=\"Thanks, and which version was released in 2002?\"\n",
    "\n",
    "run1_followup = web_agent.invoke(\n",
    "    query=query1_followup,\n",
    "    session_id=sessionid1\n",
    ")\n",
    "\n",
    "messages_followup = run1_followup.get_final_state()[\"messages\"]\n",
    "# print(\"\\nMessages from run 1 (followup):\")\n",
    "# print_messages(messages_followup)         # To print much more information\n",
    "print(\"-\" * 30)\n",
    "print(f\"Query: {query1_followup}\")\n",
    "print_agent_answer(messages_followup)\n",
    "print(\"-\" * 50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61bbe961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For debugging and improvements: \n",
    "# print(messages)\n",
    "# print_messages(messages=messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba8d3b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: message_prep\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Terminating: __termination__\n",
      "------------------------------\n",
      "Query: Which one was the first 3D platformer Mario game?\n",
      "Final answer from the agent: The first 3D platformer Mario game was \"Super Mario 64,\" released in 1996 for the Nintendo 64. This information was retrieved from the internal database.\n",
      "The agent called these tools (in order): ['retrieve_game', 'evaluate_retrieval']\n"
     ]
    }
   ],
   "source": [
    "query2=\"Which one was the first 3D platformer Mario game?\"\n",
    "sessionid2=\"mario\"\n",
    "run2 = web_agent.invoke(\n",
    "    query=query2,\n",
    "    session_id=sessionid2,\n",
    ")\n",
    "\n",
    "messages = run2.get_final_state()[\"messages\"]\n",
    "# print(\"\\nMessages from run 2:\")\n",
    "# print_messages(messages)  # To print much more information\n",
    "print(\"-\" * 30)\n",
    "print(f\"Query: {query2}\")\n",
    "print_agent_answer(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef1bca25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: message_prep\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Terminating: __termination__\n",
      "------------------------------\n",
      "Query: Was Mortal Kombat X realeased for Playstation 5?\n",
      "Final answer from the agent: Mortal Kombat X was originally released on April 14, 2015, for PlayStation 4. It is playable on PlayStation 5 through backward compatibility, but some features may be absent. The game can be updated to the latest system software on PS5 for better compatibility. This information was found on the PlayStation Store and other sources. \n",
      "\n",
      "You can see more details here: [PlayStation Store - Mortal Kombat X](https://store.playstation.com/en-us/product/UP1018-CUSA00967_00-MORTALKOMBATX000).\n",
      "The agent called these tools (in order): ['retrieve_game', 'evaluate_retrieval', 'game_web_search']\n"
     ]
    }
   ],
   "source": [
    "query3=\"Was Mortal Kombat X realeased for Playstation 5?\"\n",
    "sessionid3=\"mortal\"\n",
    "\n",
    "run3 = web_agent.invoke(\n",
    "    query=query3,\n",
    "    session_id=sessionid3,\n",
    ")\n",
    "\n",
    "messages = run3.get_final_state()[\"messages\"]\n",
    "# print(\"\\nMessages from run 3:\")\n",
    "# print_messages(messages)          # To print much more information\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(f\"Query: {query3}\")\n",
    "print_agent_answer(messages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a55081",
   "metadata": {},
   "source": [
    "### (Optional) Advanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb83fbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Update your agent with long-term memory\n",
    "# TODO: Convert the agent to be a state machine, with the tools being pre-defined nodes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
