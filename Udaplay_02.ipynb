{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fdd0bcb",
   "metadata": {},
   "source": [
    "# Udaplay Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9325b035",
   "metadata": {},
   "source": [
    "## Part 02 - Agent\n",
    "\n",
    "In this part of the project, you'll use your VectorDB to be part of your Agent as a tool.\n",
    "\n",
    "You're building UdaPlay, an AI Research Agent for the video game industry. The agent will:\n",
    "1. Answer questions using internal knowledge (RAG)\n",
    "2. Search the web when needed\n",
    "3. Maintain conversation state\n",
    "4. Return structured outputs\n",
    "5. Store useful information for future use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b42de90",
   "metadata": {},
   "source": [
    "### Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a963d4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only needed for Udacity workspace\n",
    "\n",
    "import importlib.util\n",
    "import sys\n",
    "\n",
    "# Check if 'pysqlite3' is available before importing\n",
    "if importlib.util.find_spec(\"pysqlite3\") is not None:\n",
    "    import pysqlite3\n",
    "    sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fd10c06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For example: \n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from typing import List, Any, Annotated\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from lib.agents import Agent\n",
    "from lib.llm import LLM\n",
    "from lib.messages import UserMessage, SystemMessage, ToolMessage, AIMessage\n",
    "from lib.tooling import tool\n",
    "from lib.parsers import PydanticOutputParser, JsonOutputParser\n",
    "\n",
    "from chromadb import PersistentClient\n",
    "import chromadb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "87e465d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "VOCAREUM_OPENAI_API_KEY=os.getenv(\"VOCAREUM_OPENAI_API_KEY\")\n",
    "VOCAREUM_BASE_URL=os.getenv(\"VOCAREUM_BASE_URL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0955006",
   "metadata": {},
   "source": [
    "Setting up ChromaDB paths and names. Should be consistent with what you used in the `Udaplay_01.ipynb` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1614303d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHROMADB_PATH = \"chromadb\"\n",
    "CHROMADB_COLLECTION_NAME = \"udaplay\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce364221",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27de4729",
   "metadata": {},
   "source": [
    "### Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ab2dac",
   "metadata": {},
   "source": [
    "Build at least 3 tools:\n",
    "- retrieve_game: To search the vector DB\n",
    "- evaluate_retrieval: To assess the retrieval performance\n",
    "- game_web_search: If no good, search the web\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4f14cd",
   "metadata": {},
   "source": [
    "#### Retrieve Game Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25c36dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_game(query: str, n_results: int=4) -> List:\n",
    "    \"\"\"\n",
    "#    Semantic search: Finds most relevant results in the vector DB\n",
    "#    args:\n",
    "#    - query: a question about game industry. \n",
    "#    - n_results: number of results to return (default is 4)\n",
    "#\n",
    "#    You'll receive results as list. Each element contains:\n",
    "#    - Platform: like Game Boy, Playstation 5, Xbox 360...)\n",
    "#    - Name: Name of the Game\n",
    "#    - YearOfRelease: Year when that game was released for that platform\n",
    "#    - Description: Additional details about the game\n",
    "    \"\"\"\n",
    "\n",
    "    # collection.query(\n",
    "        # query_texts=[query],\n",
    "        # n_results=n_results,\n",
    "        # include=['metadatas', 'documents', 'distances'] # TODO: look at collection.peek() to understand this better.\n",
    "    # )\n",
    "\n",
    "    # These have been created in Phase 1\n",
    "    chroma_client = PersistentClient(path=CHROMADB_PATH)\n",
    "    collection = chroma_client.get_collection(CHROMADB_COLLECTION_NAME)\n",
    "\n",
    "    results = collection.query(\n",
    "        query_texts=[query], \n",
    "        n_results=5\n",
    "        )\n",
    "    \n",
    "    return results[\"documents\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2cf8a174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To test the function\n",
    "query = \"Tell me about Gran Turismo\"\n",
    "# response = retrieve_game(query)\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910dc945",
   "metadata": {},
   "source": [
    "#### Evaluate Retrieval Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9d014b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvaluationReport(BaseModel):\n",
    "    useful: bool = Field(..., description=\"Indicates if the retrieved documents are useful for answering the question\")\n",
    "    description: str = Field(..., description=\"Detailed explanation of the evaluation result, including why the documents are or are not useful\")\n",
    "\n",
    "\n",
    "def evaluate_retrieval(question: str, retrieved_docs: list) -> dict:\n",
    "    \"\"\"\n",
    "    Based on the user's question and on the list of retrieved documents, this function \n",
    "    will analyze the usability of the documents to respond to that question. \n",
    "    args: \n",
    "    - question: original question from user\n",
    "    - retrieved_docs: retrieved documents most similar to the user query in the Vector Database\n",
    "    Outputs:\n",
    "    - useful: whether the documents are useful to answer the question\n",
    "    - description: description about the evaluation result\n",
    "    \"\"\"\n",
    "\n",
    "    system_prompt = \"\"\"\n",
    "        You are an expert in evaluating the usability of documents for answering user queries.\n",
    "        Your task is to evaluate if the provided sources are enough to respond the user query.\n",
    "        Give a detailed explanation, so it's possible to take an action to accept it or not.\n",
    "    \"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "        User query:\\n{question}\\n\n",
    "        Retrieved documents:\\n{retrieved_docs}\n",
    "    \"\"\"\n",
    "\n",
    "    messages = [\n",
    "        SystemMessage(content=system_prompt),\n",
    "        UserMessage(content=user_prompt)\n",
    "    ]\n",
    "\n",
    "    llm_judge = LLM(\n",
    "        model=\"gpt-4.1-nano\",\n",
    "        temperature=0.0,\n",
    "        api_key=VOCAREUM_OPENAI_API_KEY,\n",
    "        base_url=VOCAREUM_BASE_URL\n",
    "    )\n",
    "\n",
    "    ai_message = llm_judge.invoke(input=messages, response_format=EvaluationReport)\n",
    "    parser = JsonOutputParser()\n",
    "    return parser.parse(ai_message)\n",
    "\n",
    "\n",
    "# Use EvaluationReport to parse the result\n",
    "# Tool Docstring:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b5d7f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Is the result useful? \n",
      "    True\n",
      "\n",
      "    Detailed explanation:\n",
      "    The retrieved documents include detailed information about the Gran Turismo series, including its different versions such as Gran Turismo 5 for PlayStation 3 and the original Gran Turismo for PlayStation 1. These descriptions highlight that Gran Turismo is a racing simulator with realistic physics, a wide selection of cars and tracks, and a significant impact on the racing game genre. Although some documents mention other games like Grand Theft Auto and Mario Kart, the relevant entries about Gran Turismo provide sufficient context to answer user queries about the game, its features, and its history.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To test the function\n",
    "response_valid = evaluate_retrieval(query, response)\n",
    "validated_response = EvaluationReport(**response_valid) # To validate format adheres to EvaluationReport\n",
    "print(f\"\"\"\n",
    "    Is the result useful? \n",
    "    {validated_response.useful}\n",
    "\n",
    "    Detailed explanation:\n",
    "    {validated_response.description}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c062fe3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c7935a26",
   "metadata": {},
   "source": [
    "#### Game Web Search Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad698aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create game_web_search tool\n",
    "# Please use Tavily client to search the web\n",
    "# Tool Docstring:\n",
    "#    Semantic search: Finds most results in the vector DB\n",
    "#    args:\n",
    "#    - question: a question about game industry. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df844b3b",
   "metadata": {},
   "source": [
    "### Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c56281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create your Agent abstraction using StateMachine\n",
    "# Equip with an appropriate model\n",
    "# Craft a good set of instructions \n",
    "# Plug all Tools you developed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec23893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Invoke your agent\n",
    "# - When Pokémon Gold and Silver was released?\n",
    "# - Which one was the first 3D platformer Mario game?\n",
    "# - Was Mortal Kombat X realeased for Playstation 5?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a55081",
   "metadata": {},
   "source": [
    "### (Optional) Advanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb83fbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Update your agent with long-term memory\n",
    "# TODO: Convert the agent to be a state machine, with the tools being pre-defined nodes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
